{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "cac210ac",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "train_outpatient = pd.read_csv('../../../Dataset/archive/Train_Outpatientdata-1542865627584.csv')\n",
    "train_inpatient = pd.read_csv('../../../Dataset/archive/Train_Inpatientdata-1542865627584.csv')\n",
    "train_provider_label = pd.read_csv('../../../Dataset/archive/Train-1542865627584.csv')\n",
    "train_beneficiary_data = pd.read_csv('../../../Dataset/archive/Train_Beneficiarydata-1542865627584.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 107,
   "id": "bdc202c0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Index(['BeneID', 'ClaimID', 'ClaimStartDt', 'ClaimEndDt', 'Provider',\n",
      "       'InscClaimAmtReimbursed', 'AttendingPhysician', 'OperatingPhysician',\n",
      "       'OtherPhysician', 'ClmDiagnosisCode_1', 'ClmDiagnosisCode_2',\n",
      "       'ClmDiagnosisCode_3', 'ClmDiagnosisCode_4', 'ClmDiagnosisCode_5',\n",
      "       'ClmDiagnosisCode_6', 'ClmDiagnosisCode_7', 'ClmDiagnosisCode_8',\n",
      "       'ClmDiagnosisCode_9', 'ClmDiagnosisCode_10', 'ClmProcedureCode_1',\n",
      "       'ClmProcedureCode_2', 'ClmProcedureCode_3', 'ClmProcedureCode_4',\n",
      "       'ClmProcedureCode_5', 'ClmProcedureCode_6', 'DeductibleAmtPaid',\n",
      "       'ClmAdmitDiagnosisCode'],\n",
      "      dtype='object')\n",
      "Index(['BeneID', 'ClaimID', 'ClaimStartDt', 'ClaimEndDt', 'Provider',\n",
      "       'InscClaimAmtReimbursed', 'AttendingPhysician', 'OperatingPhysician',\n",
      "       'OtherPhysician', 'AdmissionDt', 'ClmAdmitDiagnosisCode',\n",
      "       'DeductibleAmtPaid', 'DischargeDt', 'DiagnosisGroupCode',\n",
      "       'ClmDiagnosisCode_1', 'ClmDiagnosisCode_2', 'ClmDiagnosisCode_3',\n",
      "       'ClmDiagnosisCode_4', 'ClmDiagnosisCode_5', 'ClmDiagnosisCode_6',\n",
      "       'ClmDiagnosisCode_7', 'ClmDiagnosisCode_8', 'ClmDiagnosisCode_9',\n",
      "       'ClmDiagnosisCode_10', 'ClmProcedureCode_1', 'ClmProcedureCode_2',\n",
      "       'ClmProcedureCode_3', 'ClmProcedureCode_4', 'ClmProcedureCode_5',\n",
      "       'ClmProcedureCode_6'],\n",
      "      dtype='object')\n"
     ]
    }
   ],
   "source": [
    "print(train_outpatient.columns)\n",
    "print(train_inpatient.columns)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 108,
   "id": "4e97fb90",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Index(['Provider', 'PotentialFraud'], dtype='object')\n",
      "Index(['BeneID', 'DOB', 'DOD', 'Gender', 'Race', 'RenalDiseaseIndicator',\n",
      "       'State', 'County', 'NoOfMonths_PartACov', 'NoOfMonths_PartBCov',\n",
      "       'ChronicCond_Alzheimer', 'ChronicCond_Heartfailure',\n",
      "       'ChronicCond_KidneyDisease', 'ChronicCond_Cancer',\n",
      "       'ChronicCond_ObstrPulmonary', 'ChronicCond_Depression',\n",
      "       'ChronicCond_Diabetes', 'ChronicCond_IschemicHeart',\n",
      "       'ChronicCond_Osteoporasis', 'ChronicCond_rheumatoidarthritis',\n",
      "       'ChronicCond_stroke', 'IPAnnualReimbursementAmt',\n",
      "       'IPAnnualDeductibleAmt', 'OPAnnualReimbursementAmt',\n",
      "       'OPAnnualDeductibleAmt'],\n",
      "      dtype='object')\n"
     ]
    }
   ],
   "source": [
    "print(train_provider_label.columns)\n",
    "print(train_beneficiary_data.columns)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 109,
   "id": "7d4546d4",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>BeneID</th>\n",
       "      <th>DOB</th>\n",
       "      <th>DOD</th>\n",
       "      <th>Gender</th>\n",
       "      <th>Race</th>\n",
       "      <th>RenalDiseaseIndicator</th>\n",
       "      <th>State</th>\n",
       "      <th>County</th>\n",
       "      <th>NoOfMonths_PartACov</th>\n",
       "      <th>NoOfMonths_PartBCov</th>\n",
       "      <th>...</th>\n",
       "      <th>ChronicCond_Depression</th>\n",
       "      <th>ChronicCond_Diabetes</th>\n",
       "      <th>ChronicCond_IschemicHeart</th>\n",
       "      <th>ChronicCond_Osteoporasis</th>\n",
       "      <th>ChronicCond_rheumatoidarthritis</th>\n",
       "      <th>ChronicCond_stroke</th>\n",
       "      <th>IPAnnualReimbursementAmt</th>\n",
       "      <th>IPAnnualDeductibleAmt</th>\n",
       "      <th>OPAnnualReimbursementAmt</th>\n",
       "      <th>OPAnnualDeductibleAmt</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>BENE11001</td>\n",
       "      <td>1943-01-01</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>39</td>\n",
       "      <td>230</td>\n",
       "      <td>12</td>\n",
       "      <td>12</td>\n",
       "      <td>...</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>36000</td>\n",
       "      <td>3204</td>\n",
       "      <td>60</td>\n",
       "      <td>70</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>BENE11002</td>\n",
       "      <td>1936-09-01</td>\n",
       "      <td>NaN</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>39</td>\n",
       "      <td>280</td>\n",
       "      <td>12</td>\n",
       "      <td>12</td>\n",
       "      <td>...</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>30</td>\n",
       "      <td>50</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>BENE11003</td>\n",
       "      <td>1936-08-01</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>52</td>\n",
       "      <td>590</td>\n",
       "      <td>12</td>\n",
       "      <td>12</td>\n",
       "      <td>...</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>90</td>\n",
       "      <td>40</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>BENE11004</td>\n",
       "      <td>1922-07-01</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>39</td>\n",
       "      <td>270</td>\n",
       "      <td>12</td>\n",
       "      <td>12</td>\n",
       "      <td>...</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1810</td>\n",
       "      <td>760</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>BENE11005</td>\n",
       "      <td>1935-09-01</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>24</td>\n",
       "      <td>680</td>\n",
       "      <td>12</td>\n",
       "      <td>12</td>\n",
       "      <td>...</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1790</td>\n",
       "      <td>1200</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 25 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "      BeneID         DOB  DOD  Gender  Race RenalDiseaseIndicator  State  \\\n",
       "0  BENE11001  1943-01-01  NaN       1     1                     0     39   \n",
       "1  BENE11002  1936-09-01  NaN       2     1                     0     39   \n",
       "2  BENE11003  1936-08-01  NaN       1     1                     0     52   \n",
       "3  BENE11004  1922-07-01  NaN       1     1                     0     39   \n",
       "4  BENE11005  1935-09-01  NaN       1     1                     0     24   \n",
       "\n",
       "   County  NoOfMonths_PartACov  NoOfMonths_PartBCov  ...  \\\n",
       "0     230                   12                   12  ...   \n",
       "1     280                   12                   12  ...   \n",
       "2     590                   12                   12  ...   \n",
       "3     270                   12                   12  ...   \n",
       "4     680                   12                   12  ...   \n",
       "\n",
       "   ChronicCond_Depression  ChronicCond_Diabetes  ChronicCond_IschemicHeart  \\\n",
       "0                       1                     1                          1   \n",
       "1                       2                     2                          2   \n",
       "2                       2                     2                          1   \n",
       "3                       2                     1                          1   \n",
       "4                       2                     1                          2   \n",
       "\n",
       "   ChronicCond_Osteoporasis  ChronicCond_rheumatoidarthritis  \\\n",
       "0                         2                                1   \n",
       "1                         2                                2   \n",
       "2                         2                                2   \n",
       "3                         1                                1   \n",
       "4                         2                                2   \n",
       "\n",
       "   ChronicCond_stroke  IPAnnualReimbursementAmt  IPAnnualDeductibleAmt  \\\n",
       "0                   1                     36000                   3204   \n",
       "1                   2                         0                      0   \n",
       "2                   2                         0                      0   \n",
       "3                   2                         0                      0   \n",
       "4                   2                         0                      0   \n",
       "\n",
       "   OPAnnualReimbursementAmt  OPAnnualDeductibleAmt  \n",
       "0                        60                     70  \n",
       "1                        30                     50  \n",
       "2                        90                     40  \n",
       "3                      1810                    760  \n",
       "4                      1790                   1200  \n",
       "\n",
       "[5 rows x 25 columns]"
      ]
     },
     "execution_count": 109,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_beneficiary_data.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 110,
   "id": "d5c8881d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>BeneID</th>\n",
       "      <th>ClaimID</th>\n",
       "      <th>ClaimStartDt</th>\n",
       "      <th>ClaimEndDt</th>\n",
       "      <th>Provider</th>\n",
       "      <th>InscClaimAmtReimbursed</th>\n",
       "      <th>AttendingPhysician</th>\n",
       "      <th>OperatingPhysician</th>\n",
       "      <th>OtherPhysician</th>\n",
       "      <th>AdmissionDt</th>\n",
       "      <th>...</th>\n",
       "      <th>ClmDiagnosisCode_7</th>\n",
       "      <th>ClmDiagnosisCode_8</th>\n",
       "      <th>ClmDiagnosisCode_9</th>\n",
       "      <th>ClmDiagnosisCode_10</th>\n",
       "      <th>ClmProcedureCode_1</th>\n",
       "      <th>ClmProcedureCode_2</th>\n",
       "      <th>ClmProcedureCode_3</th>\n",
       "      <th>ClmProcedureCode_4</th>\n",
       "      <th>ClmProcedureCode_5</th>\n",
       "      <th>ClmProcedureCode_6</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>BENE11001</td>\n",
       "      <td>CLM46614</td>\n",
       "      <td>2009-04-12</td>\n",
       "      <td>2009-04-18</td>\n",
       "      <td>PRV55912</td>\n",
       "      <td>26000</td>\n",
       "      <td>PHY390922</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>2009-04-12</td>\n",
       "      <td>...</td>\n",
       "      <td>2724</td>\n",
       "      <td>19889</td>\n",
       "      <td>5849</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>BENE11001</td>\n",
       "      <td>CLM66048</td>\n",
       "      <td>2009-08-31</td>\n",
       "      <td>2009-09-02</td>\n",
       "      <td>PRV55907</td>\n",
       "      <td>5000</td>\n",
       "      <td>PHY318495</td>\n",
       "      <td>PHY318495</td>\n",
       "      <td>NaN</td>\n",
       "      <td>2009-08-31</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>7092.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>BENE11001</td>\n",
       "      <td>CLM68358</td>\n",
       "      <td>2009-09-17</td>\n",
       "      <td>2009-09-20</td>\n",
       "      <td>PRV56046</td>\n",
       "      <td>5000</td>\n",
       "      <td>PHY372395</td>\n",
       "      <td>NaN</td>\n",
       "      <td>PHY324689</td>\n",
       "      <td>2009-09-17</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>BENE11011</td>\n",
       "      <td>CLM38412</td>\n",
       "      <td>2009-02-14</td>\n",
       "      <td>2009-02-22</td>\n",
       "      <td>PRV52405</td>\n",
       "      <td>5000</td>\n",
       "      <td>PHY369659</td>\n",
       "      <td>PHY392961</td>\n",
       "      <td>PHY349768</td>\n",
       "      <td>2009-02-14</td>\n",
       "      <td>...</td>\n",
       "      <td>25062</td>\n",
       "      <td>40390</td>\n",
       "      <td>4019</td>\n",
       "      <td>NaN</td>\n",
       "      <td>331.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>BENE11014</td>\n",
       "      <td>CLM63689</td>\n",
       "      <td>2009-08-13</td>\n",
       "      <td>2009-08-30</td>\n",
       "      <td>PRV56614</td>\n",
       "      <td>10000</td>\n",
       "      <td>PHY379376</td>\n",
       "      <td>PHY398258</td>\n",
       "      <td>NaN</td>\n",
       "      <td>2009-08-13</td>\n",
       "      <td>...</td>\n",
       "      <td>5119</td>\n",
       "      <td>29620</td>\n",
       "      <td>20300</td>\n",
       "      <td>NaN</td>\n",
       "      <td>3893.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 30 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "      BeneID   ClaimID ClaimStartDt  ClaimEndDt  Provider  \\\n",
       "0  BENE11001  CLM46614   2009-04-12  2009-04-18  PRV55912   \n",
       "1  BENE11001  CLM66048   2009-08-31  2009-09-02  PRV55907   \n",
       "2  BENE11001  CLM68358   2009-09-17  2009-09-20  PRV56046   \n",
       "3  BENE11011  CLM38412   2009-02-14  2009-02-22  PRV52405   \n",
       "4  BENE11014  CLM63689   2009-08-13  2009-08-30  PRV56614   \n",
       "\n",
       "   InscClaimAmtReimbursed AttendingPhysician OperatingPhysician  \\\n",
       "0                   26000          PHY390922                NaN   \n",
       "1                    5000          PHY318495          PHY318495   \n",
       "2                    5000          PHY372395                NaN   \n",
       "3                    5000          PHY369659          PHY392961   \n",
       "4                   10000          PHY379376          PHY398258   \n",
       "\n",
       "  OtherPhysician AdmissionDt  ... ClmDiagnosisCode_7  ClmDiagnosisCode_8  \\\n",
       "0            NaN  2009-04-12  ...               2724               19889   \n",
       "1            NaN  2009-08-31  ...                NaN                 NaN   \n",
       "2      PHY324689  2009-09-17  ...                NaN                 NaN   \n",
       "3      PHY349768  2009-02-14  ...              25062               40390   \n",
       "4            NaN  2009-08-13  ...               5119               29620   \n",
       "\n",
       "  ClmDiagnosisCode_9 ClmDiagnosisCode_10 ClmProcedureCode_1  \\\n",
       "0               5849                 NaN                NaN   \n",
       "1                NaN                 NaN             7092.0   \n",
       "2                NaN                 NaN                NaN   \n",
       "3               4019                 NaN              331.0   \n",
       "4              20300                 NaN             3893.0   \n",
       "\n",
       "  ClmProcedureCode_2 ClmProcedureCode_3 ClmProcedureCode_4 ClmProcedureCode_5  \\\n",
       "0                NaN                NaN                NaN                NaN   \n",
       "1                NaN                NaN                NaN                NaN   \n",
       "2                NaN                NaN                NaN                NaN   \n",
       "3                NaN                NaN                NaN                NaN   \n",
       "4                NaN                NaN                NaN                NaN   \n",
       "\n",
       "  ClmProcedureCode_6  \n",
       "0                NaN  \n",
       "1                NaN  \n",
       "2                NaN  \n",
       "3                NaN  \n",
       "4                NaN  \n",
       "\n",
       "[5 rows x 30 columns]"
      ]
     },
     "execution_count": 110,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_inpatient.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 111,
   "id": "452f6f7c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>BeneID</th>\n",
       "      <th>ClaimID</th>\n",
       "      <th>ClaimStartDt</th>\n",
       "      <th>ClaimEndDt</th>\n",
       "      <th>Provider</th>\n",
       "      <th>InscClaimAmtReimbursed</th>\n",
       "      <th>AttendingPhysician</th>\n",
       "      <th>OperatingPhysician</th>\n",
       "      <th>OtherPhysician</th>\n",
       "      <th>ClmDiagnosisCode_1</th>\n",
       "      <th>...</th>\n",
       "      <th>ClmDiagnosisCode_9</th>\n",
       "      <th>ClmDiagnosisCode_10</th>\n",
       "      <th>ClmProcedureCode_1</th>\n",
       "      <th>ClmProcedureCode_2</th>\n",
       "      <th>ClmProcedureCode_3</th>\n",
       "      <th>ClmProcedureCode_4</th>\n",
       "      <th>ClmProcedureCode_5</th>\n",
       "      <th>ClmProcedureCode_6</th>\n",
       "      <th>DeductibleAmtPaid</th>\n",
       "      <th>ClmAdmitDiagnosisCode</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>BENE11002</td>\n",
       "      <td>CLM624349</td>\n",
       "      <td>2009-10-11</td>\n",
       "      <td>2009-10-11</td>\n",
       "      <td>PRV56011</td>\n",
       "      <td>30</td>\n",
       "      <td>PHY326117</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>78943</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0</td>\n",
       "      <td>56409</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>BENE11003</td>\n",
       "      <td>CLM189947</td>\n",
       "      <td>2009-02-12</td>\n",
       "      <td>2009-02-12</td>\n",
       "      <td>PRV57610</td>\n",
       "      <td>80</td>\n",
       "      <td>PHY362868</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>6115</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0</td>\n",
       "      <td>79380</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>BENE11003</td>\n",
       "      <td>CLM438021</td>\n",
       "      <td>2009-06-27</td>\n",
       "      <td>2009-06-27</td>\n",
       "      <td>PRV57595</td>\n",
       "      <td>10</td>\n",
       "      <td>PHY328821</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>2723</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>BENE11004</td>\n",
       "      <td>CLM121801</td>\n",
       "      <td>2009-01-06</td>\n",
       "      <td>2009-01-06</td>\n",
       "      <td>PRV56011</td>\n",
       "      <td>40</td>\n",
       "      <td>PHY334319</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>71988</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>BENE11004</td>\n",
       "      <td>CLM150998</td>\n",
       "      <td>2009-01-22</td>\n",
       "      <td>2009-01-22</td>\n",
       "      <td>PRV56011</td>\n",
       "      <td>200</td>\n",
       "      <td>PHY403831</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>82382</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0</td>\n",
       "      <td>71947</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 27 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "      BeneID    ClaimID ClaimStartDt  ClaimEndDt  Provider  \\\n",
       "0  BENE11002  CLM624349   2009-10-11  2009-10-11  PRV56011   \n",
       "1  BENE11003  CLM189947   2009-02-12  2009-02-12  PRV57610   \n",
       "2  BENE11003  CLM438021   2009-06-27  2009-06-27  PRV57595   \n",
       "3  BENE11004  CLM121801   2009-01-06  2009-01-06  PRV56011   \n",
       "4  BENE11004  CLM150998   2009-01-22  2009-01-22  PRV56011   \n",
       "\n",
       "   InscClaimAmtReimbursed AttendingPhysician OperatingPhysician  \\\n",
       "0                      30          PHY326117                NaN   \n",
       "1                      80          PHY362868                NaN   \n",
       "2                      10          PHY328821                NaN   \n",
       "3                      40          PHY334319                NaN   \n",
       "4                     200          PHY403831                NaN   \n",
       "\n",
       "  OtherPhysician ClmDiagnosisCode_1  ... ClmDiagnosisCode_9  \\\n",
       "0            NaN              78943  ...                NaN   \n",
       "1            NaN               6115  ...                NaN   \n",
       "2            NaN               2723  ...                NaN   \n",
       "3            NaN              71988  ...                NaN   \n",
       "4            NaN              82382  ...                NaN   \n",
       "\n",
       "  ClmDiagnosisCode_10 ClmProcedureCode_1 ClmProcedureCode_2  \\\n",
       "0                 NaN                NaN                NaN   \n",
       "1                 NaN                NaN                NaN   \n",
       "2                 NaN                NaN                NaN   \n",
       "3                 NaN                NaN                NaN   \n",
       "4                 NaN                NaN                NaN   \n",
       "\n",
       "  ClmProcedureCode_3 ClmProcedureCode_4 ClmProcedureCode_5 ClmProcedureCode_6  \\\n",
       "0                NaN                NaN                NaN                NaN   \n",
       "1                NaN                NaN                NaN                NaN   \n",
       "2                NaN                NaN                NaN                NaN   \n",
       "3                NaN                NaN                NaN                NaN   \n",
       "4                NaN                NaN                NaN                NaN   \n",
       "\n",
       "  DeductibleAmtPaid  ClmAdmitDiagnosisCode  \n",
       "0                 0                  56409  \n",
       "1                 0                  79380  \n",
       "2                 0                    NaN  \n",
       "3                 0                    NaN  \n",
       "4                 0                  71947  \n",
       "\n",
       "[5 rows x 27 columns]"
      ]
     },
     "execution_count": 111,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_outpatient.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 112,
   "id": "fb874352",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Provider</th>\n",
       "      <th>PotentialFraud</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>PRV51001</td>\n",
       "      <td>No</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>PRV51003</td>\n",
       "      <td>Yes</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>PRV51004</td>\n",
       "      <td>No</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>PRV51005</td>\n",
       "      <td>Yes</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>PRV51007</td>\n",
       "      <td>No</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   Provider PotentialFraud\n",
       "0  PRV51001             No\n",
       "1  PRV51003            Yes\n",
       "2  PRV51004             No\n",
       "3  PRV51005            Yes\n",
       "4  PRV51007             No"
      ]
     },
     "execution_count": 112,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_provider_label.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 113,
   "id": "74439b6f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "BeneID                         0\n",
      "ClaimID                        0\n",
      "ClaimStartDt                   0\n",
      "ClaimEndDt                     0\n",
      "Provider                       0\n",
      "InscClaimAmtReimbursed         0\n",
      "AttendingPhysician          1396\n",
      "OperatingPhysician        427120\n",
      "OtherPhysician            322691\n",
      "ClmDiagnosisCode_1         10453\n",
      "ClmDiagnosisCode_2        195380\n",
      "ClmDiagnosisCode_3        314480\n",
      "ClmDiagnosisCode_4        392141\n",
      "ClmDiagnosisCode_5        443393\n",
      "ClmDiagnosisCode_6        468981\n",
      "ClmDiagnosisCode_7        484776\n",
      "ClmDiagnosisCode_8        494825\n",
      "ClmDiagnosisCode_9        502899\n",
      "ClmDiagnosisCode_10       516654\n",
      "ClmProcedureCode_1        517575\n",
      "ClmProcedureCode_2        517701\n",
      "ClmProcedureCode_3        517733\n",
      "ClmProcedureCode_4        517735\n",
      "ClmProcedureCode_5        517737\n",
      "ClmProcedureCode_6        517737\n",
      "DeductibleAmtPaid              0\n",
      "ClmAdmitDiagnosisCode     412312\n",
      "dtype: int64\n",
      "BeneID                        0\n",
      "ClaimID                       0\n",
      "ClaimStartDt                  0\n",
      "ClaimEndDt                    0\n",
      "Provider                      0\n",
      "InscClaimAmtReimbursed        0\n",
      "AttendingPhysician          112\n",
      "OperatingPhysician        16644\n",
      "OtherPhysician            35784\n",
      "AdmissionDt                   0\n",
      "ClmAdmitDiagnosisCode         0\n",
      "DeductibleAmtPaid           899\n",
      "DischargeDt                   0\n",
      "DiagnosisGroupCode            0\n",
      "ClmDiagnosisCode_1            0\n",
      "ClmDiagnosisCode_2          226\n",
      "ClmDiagnosisCode_3          676\n",
      "ClmDiagnosisCode_4         1534\n",
      "ClmDiagnosisCode_5         2894\n",
      "ClmDiagnosisCode_6         4838\n",
      "ClmDiagnosisCode_7         7258\n",
      "ClmDiagnosisCode_8         9942\n",
      "ClmDiagnosisCode_9        13497\n",
      "ClmDiagnosisCode_10       36547\n",
      "ClmProcedureCode_1        17326\n",
      "ClmProcedureCode_2        35020\n",
      "ClmProcedureCode_3        39509\n",
      "ClmProcedureCode_4        40358\n",
      "ClmProcedureCode_5        40465\n",
      "ClmProcedureCode_6        40474\n",
      "dtype: int64\n",
      "BeneID                                  0\n",
      "DOB                                     0\n",
      "DOD                                137135\n",
      "Gender                                  0\n",
      "Race                                    0\n",
      "RenalDiseaseIndicator                   0\n",
      "State                                   0\n",
      "County                                  0\n",
      "NoOfMonths_PartACov                     0\n",
      "NoOfMonths_PartBCov                     0\n",
      "ChronicCond_Alzheimer                   0\n",
      "ChronicCond_Heartfailure                0\n",
      "ChronicCond_KidneyDisease               0\n",
      "ChronicCond_Cancer                      0\n",
      "ChronicCond_ObstrPulmonary              0\n",
      "ChronicCond_Depression                  0\n",
      "ChronicCond_Diabetes                    0\n",
      "ChronicCond_IschemicHeart               0\n",
      "ChronicCond_Osteoporasis                0\n",
      "ChronicCond_rheumatoidarthritis         0\n",
      "ChronicCond_stroke                      0\n",
      "IPAnnualReimbursementAmt                0\n",
      "IPAnnualDeductibleAmt                   0\n",
      "OPAnnualReimbursementAmt                0\n",
      "OPAnnualDeductibleAmt                   0\n",
      "dtype: int64\n",
      "Provider          0\n",
      "PotentialFraud    0\n",
      "dtype: int64\n"
     ]
    }
   ],
   "source": [
    "print(train_outpatient.isnull().sum())\n",
    "print(train_inpatient.isnull().sum())\n",
    "print(train_beneficiary_data.isnull().sum())\n",
    "print(train_provider_label.isnull().sum())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "6854c9fc",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Common columns: 27\n",
      "Columns only in inpatient: {'AdmissionDt', 'DischargeDt', 'DiagnosisGroupCode'}\n",
      "Columns only in outpatient: set()\n"
     ]
    }
   ],
   "source": [
    "inpatient_columns = set(train_inpatient.columns)\n",
    "outpatient_columns = set(train_outpatient.columns)\n",
    "common_columns = inpatient_columns.intersection(outpatient_columns)\n",
    "inpatient_only = inpatient_columns - outpatient_columns\n",
    "\n",
    "outpatient_only = outpatient_columns - inpatient_columns\n",
    "\n",
    "print(f\"Common columns: {len(common_columns)}\")\n",
    "print(f\"Columns only in inpatient: {inpatient_only}\")\n",
    "print(f\"Columns only in outpatient: {outpatient_only}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "a07ba5d9",
   "metadata": {},
   "outputs": [],
   "source": [
    "# For inpatient data, add any columns that are in outpatient but not in inpatient\n",
    "for col in outpatient_only:\n",
    "    train_inpatient[col] = None\n",
    "    \n",
    "# For outpatient data, add any columns that are in inpatient but not in outpatient\n",
    "for col in inpatient_only:\n",
    "    train_outpatient[col] = None\n",
    "\n",
    "train_inpatient['IP_indicator'] = 1  # 1 for inpatient\n",
    "train_outpatient['IP_indicator'] = 0  # 0 for outpatient"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "1167e504",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Combined dataset shape: (558211, 31)\n"
     ]
    }
   ],
   "source": [
    "# Concatenate the two dataframes\n",
    "combined_claims = pd.concat([train_inpatient, train_outpatient], ignore_index=True)\n",
    "\n",
    "# Check the shape of the combined dataset\n",
    "print(f\"Combined dataset shape: {combined_claims.shape}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "c6bf0b2d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Combined with beneficiary dataset shape: (558211, 55)\n"
     ]
    }
   ],
   "source": [
    "# # Step 1: Identify the key beneficiary columns to include\n",
    "# beneficiary_cols = ['BeneID', 'DOB', 'Gender', 'Race', 'State', 'County', \n",
    "#                    'ChronicCond_Alzheimer', 'ChronicCond_Heartfailure', \n",
    "#                    'ChronicCond_KidneyDisease', 'ChronicCond_Cancer',\n",
    "#                    'ChronicCond_ObstrPulmonary', 'ChronicCond_Depression',\n",
    "#                    'ChronicCond_Diabetes', 'ChronicCond_IschemicHeart',\n",
    "#                    'ChronicCond_Osteoporasis', 'ChronicCond_rheumatoidarthritis',\n",
    "#                    'ChronicCond_stroke']\n",
    "\n",
    "# Step 2: Merge the combined claims data with beneficiary data\n",
    "combined_with_beneficiary = combined_claims.merge(\n",
    "    train_beneficiary_data, \n",
    "    on='BeneID',  # Join on the beneficiary ID\n",
    "    how='left'    # Use left join to keep all claims records\n",
    ")\n",
    "\n",
    "# Check the shape of the merged dataset\n",
    "print(f\"Combined with beneficiary dataset shape: {combined_with_beneficiary.shape}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "0938833d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Final dataset shape: (558211, 56)\n",
      "\n",
      "Sample of final dataset:\n",
      "\n",
      "Fraud distribution (%):\n",
      "PotentialFraud\n",
      "No     345415\n",
      "Yes    212796\n",
      "Name: count, dtype: int64\n",
      "\n",
      "Fraud distribution (%):\n",
      "PotentialFraud\n",
      "No     61.878931\n",
      "Yes    38.121069\n",
      "Name: proportion, dtype: float64\n"
     ]
    }
   ],
   "source": [
    "# Step 3: Merge with Provider fraud labels\n",
    "final_data = combined_with_beneficiary.merge(\n",
    "    train_provider_label,  # Dataset containing provider fraud labels\n",
    "    on='Provider',         # Join on the Provider ID\n",
    "    how='left'             # Use left join to keep all claims records\n",
    ")\n",
    "\n",
    "# Check the shape and preview the final dataset\n",
    "print(f\"Final dataset shape: {final_data.shape}\")\n",
    "print(\"\\nSample of final dataset:\")\n",
    "final_data.head()\n",
    "\n",
    "# Check the distribution of fraud labels\n",
    "fraud_count = final_data['PotentialFraud'].value_counts()\n",
    "fraud_distribution = final_data['PotentialFraud'].value_counts(normalize=True) * 100\n",
    "print(f\"\\nFraud distribution (%):\\n{fraud_count}\")\n",
    "print(f\"\\nFraud distribution (%):\\n{fraud_distribution}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "4ae4a93f",
   "metadata": {},
   "outputs": [],
   "source": [
    "final_data['AttendingPhysician'] = final_data['AttendingPhysician'].fillna(0)\n",
    "final_data['OperatingPhysician'] = final_data['OperatingPhysician'].fillna(0)\n",
    "final_data['OtherPhysician'] = final_data['OtherPhysician'].fillna(0)\n",
    "\n",
    "for i in range(1, 11):\n",
    "    col = f'ClmDiagnosisCode_{i}'\n",
    "    if col in final_data.columns:\n",
    "        final_data[col] = final_data[col].fillna('UNKNOWN')\n",
    "for i in range(1, 7):\n",
    "    col = f'ClmProcedureCode_{i}'\n",
    "    if col in final_data.columns:\n",
    "        final_data[col] = final_data[col].fillna(0)\n",
    "\n",
    "# Handle ClmAdmitDiagnosisCode\n",
    "if 'ClmAdmitDiagnosisCode' in final_data.columns:\n",
    "    final_data['ClmAdmitDiagnosisCode'] = final_data['ClmAdmitDiagnosisCode'].fillna('UNKNOWN')\n",
    "        \n",
    "# Fill missing DeductibleAmtPaid with 0\n",
    "if 'DeductibleAmtPaid' in final_data.columns:\n",
    "    final_data['DeductibleAmtPaid'] = final_data['DeductibleAmtPaid'].fillna(0)\n",
    "\n",
    "final_data['RenalDiseaseIndicator'] = final_data['RenalDiseaseIndicator'].map({'Y':1, '0':0})\n",
    "\n",
    "final_data['Patient_Deceased'] = final_data['DOD'].notna().astype(int)\n",
    "\n",
    "final_data['DOB'] = pd.to_datetime(final_data['DOB'])\n",
    "final_data['DOD'] = pd.to_datetime(final_data['DOD'])\n",
    "\n",
    "# Step 1: Convert dates and compute AdmitForDays\n",
    "final_data['AdmissionDt'] = pd.to_datetime(final_data['AdmissionDt'], errors='coerce')\n",
    "final_data['DischargeDt'] = pd.to_datetime(final_data['DischargeDt'], errors='coerce')\n",
    "final_data['AdmitForDays'] = (final_data['DischargeDt'] - final_data['AdmissionDt']).dt.days\n",
    "\n",
    "final_data['AdmitForDays'] = final_data['AdmitForDays'].fillna(0)\n",
    "\n",
    "final_data = final_data.drop(columns=['AdmissionDt','DischargeDt'])\n",
    "\n",
    "final_data['DiagnosisGroupCode'] = final_data['DiagnosisGroupCode'].fillna('UNKNOWN')\n",
    "\n",
    "final_data = final_data.drop(columns=['DOD'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "c9db5738",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "BeneID                             0\n",
       "ClaimID                            0\n",
       "ClaimStartDt                       0\n",
       "ClaimEndDt                         0\n",
       "Provider                           0\n",
       "InscClaimAmtReimbursed             0\n",
       "AttendingPhysician                 0\n",
       "OperatingPhysician                 0\n",
       "OtherPhysician                     0\n",
       "ClmAdmitDiagnosisCode              0\n",
       "DeductibleAmtPaid                  0\n",
       "DiagnosisGroupCode                 0\n",
       "ClmDiagnosisCode_1                 0\n",
       "ClmDiagnosisCode_2                 0\n",
       "ClmDiagnosisCode_3                 0\n",
       "ClmDiagnosisCode_4                 0\n",
       "ClmDiagnosisCode_5                 0\n",
       "ClmDiagnosisCode_6                 0\n",
       "ClmDiagnosisCode_7                 0\n",
       "ClmDiagnosisCode_8                 0\n",
       "ClmDiagnosisCode_9                 0\n",
       "ClmDiagnosisCode_10                0\n",
       "ClmProcedureCode_1                 0\n",
       "ClmProcedureCode_2                 0\n",
       "ClmProcedureCode_3                 0\n",
       "ClmProcedureCode_4                 0\n",
       "ClmProcedureCode_5                 0\n",
       "ClmProcedureCode_6                 0\n",
       "IP_indicator                       0\n",
       "DOB                                0\n",
       "Gender                             0\n",
       "Race                               0\n",
       "RenalDiseaseIndicator              0\n",
       "State                              0\n",
       "County                             0\n",
       "NoOfMonths_PartACov                0\n",
       "NoOfMonths_PartBCov                0\n",
       "ChronicCond_Alzheimer              0\n",
       "ChronicCond_Heartfailure           0\n",
       "ChronicCond_KidneyDisease          0\n",
       "ChronicCond_Cancer                 0\n",
       "ChronicCond_ObstrPulmonary         0\n",
       "ChronicCond_Depression             0\n",
       "ChronicCond_Diabetes               0\n",
       "ChronicCond_IschemicHeart          0\n",
       "ChronicCond_Osteoporasis           0\n",
       "ChronicCond_rheumatoidarthritis    0\n",
       "ChronicCond_stroke                 0\n",
       "IPAnnualReimbursementAmt           0\n",
       "IPAnnualDeductibleAmt              0\n",
       "OPAnnualReimbursementAmt           0\n",
       "OPAnnualDeductibleAmt              0\n",
       "PotentialFraud                     0\n",
       "Patient_Deceased                   0\n",
       "AdmitForDays                       0\n",
       "dtype: int64"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "final_data.isnull().sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "161654e3",
   "metadata": {},
   "outputs": [],
   "source": [
    "# # Save final_data as a CSV file\n",
    "# final_data.head(1000).to_csv(\"final_data.csv\", index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "b7b96edf",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 558211 entries, 0 to 558210\n",
      "Data columns (total 55 columns):\n",
      " #   Column                           Non-Null Count   Dtype         \n",
      "---  ------                           --------------   -----         \n",
      " 0   BeneID                           558211 non-null  object        \n",
      " 1   ClaimID                          558211 non-null  object        \n",
      " 2   ClaimStartDt                     558211 non-null  object        \n",
      " 3   ClaimEndDt                       558211 non-null  object        \n",
      " 4   Provider                         558211 non-null  object        \n",
      " 5   InscClaimAmtReimbursed           558211 non-null  int64         \n",
      " 6   AttendingPhysician               558211 non-null  object        \n",
      " 7   OperatingPhysician               558211 non-null  object        \n",
      " 8   OtherPhysician                   558211 non-null  object        \n",
      " 9   ClmAdmitDiagnosisCode            558211 non-null  object        \n",
      " 10  DeductibleAmtPaid                558211 non-null  float64       \n",
      " 11  DiagnosisGroupCode               558211 non-null  object        \n",
      " 12  ClmDiagnosisCode_1               558211 non-null  object        \n",
      " 13  ClmDiagnosisCode_2               558211 non-null  object        \n",
      " 14  ClmDiagnosisCode_3               558211 non-null  object        \n",
      " 15  ClmDiagnosisCode_4               558211 non-null  object        \n",
      " 16  ClmDiagnosisCode_5               558211 non-null  object        \n",
      " 17  ClmDiagnosisCode_6               558211 non-null  object        \n",
      " 18  ClmDiagnosisCode_7               558211 non-null  object        \n",
      " 19  ClmDiagnosisCode_8               558211 non-null  object        \n",
      " 20  ClmDiagnosisCode_9               558211 non-null  object        \n",
      " 21  ClmDiagnosisCode_10              558211 non-null  object        \n",
      " 22  ClmProcedureCode_1               558211 non-null  float64       \n",
      " 23  ClmProcedureCode_2               558211 non-null  float64       \n",
      " 24  ClmProcedureCode_3               558211 non-null  float64       \n",
      " 25  ClmProcedureCode_4               558211 non-null  float64       \n",
      " 26  ClmProcedureCode_5               558211 non-null  float64       \n",
      " 27  ClmProcedureCode_6               558211 non-null  float64       \n",
      " 28  IP_indicator                     558211 non-null  int64         \n",
      " 29  DOB                              558211 non-null  datetime64[ns]\n",
      " 30  Gender                           558211 non-null  int64         \n",
      " 31  Race                             558211 non-null  int64         \n",
      " 32  RenalDiseaseIndicator            558211 non-null  int64         \n",
      " 33  State                            558211 non-null  int64         \n",
      " 34  County                           558211 non-null  int64         \n",
      " 35  NoOfMonths_PartACov              558211 non-null  int64         \n",
      " 36  NoOfMonths_PartBCov              558211 non-null  int64         \n",
      " 37  ChronicCond_Alzheimer            558211 non-null  int64         \n",
      " 38  ChronicCond_Heartfailure         558211 non-null  int64         \n",
      " 39  ChronicCond_KidneyDisease        558211 non-null  int64         \n",
      " 40  ChronicCond_Cancer               558211 non-null  int64         \n",
      " 41  ChronicCond_ObstrPulmonary       558211 non-null  int64         \n",
      " 42  ChronicCond_Depression           558211 non-null  int64         \n",
      " 43  ChronicCond_Diabetes             558211 non-null  int64         \n",
      " 44  ChronicCond_IschemicHeart        558211 non-null  int64         \n",
      " 45  ChronicCond_Osteoporasis         558211 non-null  int64         \n",
      " 46  ChronicCond_rheumatoidarthritis  558211 non-null  int64         \n",
      " 47  ChronicCond_stroke               558211 non-null  int64         \n",
      " 48  IPAnnualReimbursementAmt         558211 non-null  int64         \n",
      " 49  IPAnnualDeductibleAmt            558211 non-null  int64         \n",
      " 50  OPAnnualReimbursementAmt         558211 non-null  int64         \n",
      " 51  OPAnnualDeductibleAmt            558211 non-null  int64         \n",
      " 52  PotentialFraud                   558211 non-null  object        \n",
      " 53  Patient_Deceased                 558211 non-null  int64         \n",
      " 54  AdmitForDays                     558211 non-null  float64       \n",
      "dtypes: datetime64[ns](1), float64(8), int64(25), object(21)\n",
      "memory usage: 234.2+ MB\n"
     ]
    }
   ],
   "source": [
    "final_data.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "75fdea4a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Change Physician ID to INT\n",
    "final_data['AttendingPhysician'] = final_data['AttendingPhysician'].str.removeprefix(\"PHY\").fillna(0).astype(int) + 3_000_000\n",
    "final_data['OperatingPhysician'] = final_data['OperatingPhysician'].str.removeprefix(\"PHY\").fillna(0).astype(int) + 3_000_000\n",
    "final_data['OtherPhysician'] = final_data['OtherPhysician'].str.removeprefix(\"PHY\").fillna(0).astype(int) + 3_000_000\n",
    "\n",
    "# Change Beneficiary ID to INT\n",
    "final_data['BeneID'] = final_data['BeneID'].str.removeprefix(\"BENE\").fillna(0).astype(int) +2_000_000\n",
    "\n",
    "# Change Provider ID to INT\n",
    "final_data['Provider'] = final_data['Provider'].str.removeprefix(\"PRV\").astype(int) + 1_000_000\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "0a9e7905",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 558211 entries, 0 to 558210\n",
      "Data columns (total 55 columns):\n",
      " #   Column                           Non-Null Count   Dtype         \n",
      "---  ------                           --------------   -----         \n",
      " 0   BeneID                           558211 non-null  int64         \n",
      " 1   ClaimID                          558211 non-null  object        \n",
      " 2   ClaimStartDt                     558211 non-null  object        \n",
      " 3   ClaimEndDt                       558211 non-null  object        \n",
      " 4   Provider                         558211 non-null  int64         \n",
      " 5   InscClaimAmtReimbursed           558211 non-null  int64         \n",
      " 6   AttendingPhysician               558211 non-null  int64         \n",
      " 7   OperatingPhysician               558211 non-null  int64         \n",
      " 8   OtherPhysician                   558211 non-null  int64         \n",
      " 9   ClmAdmitDiagnosisCode            558211 non-null  object        \n",
      " 10  DeductibleAmtPaid                558211 non-null  float64       \n",
      " 11  DiagnosisGroupCode               558211 non-null  object        \n",
      " 12  ClmDiagnosisCode_1               558211 non-null  object        \n",
      " 13  ClmDiagnosisCode_2               558211 non-null  object        \n",
      " 14  ClmDiagnosisCode_3               558211 non-null  object        \n",
      " 15  ClmDiagnosisCode_4               558211 non-null  object        \n",
      " 16  ClmDiagnosisCode_5               558211 non-null  object        \n",
      " 17  ClmDiagnosisCode_6               558211 non-null  object        \n",
      " 18  ClmDiagnosisCode_7               558211 non-null  object        \n",
      " 19  ClmDiagnosisCode_8               558211 non-null  object        \n",
      " 20  ClmDiagnosisCode_9               558211 non-null  object        \n",
      " 21  ClmDiagnosisCode_10              558211 non-null  object        \n",
      " 22  ClmProcedureCode_1               558211 non-null  float64       \n",
      " 23  ClmProcedureCode_2               558211 non-null  float64       \n",
      " 24  ClmProcedureCode_3               558211 non-null  float64       \n",
      " 25  ClmProcedureCode_4               558211 non-null  float64       \n",
      " 26  ClmProcedureCode_5               558211 non-null  float64       \n",
      " 27  ClmProcedureCode_6               558211 non-null  float64       \n",
      " 28  IP_indicator                     558211 non-null  int64         \n",
      " 29  DOB                              558211 non-null  datetime64[ns]\n",
      " 30  Gender                           558211 non-null  int64         \n",
      " 31  Race                             558211 non-null  int64         \n",
      " 32  RenalDiseaseIndicator            558211 non-null  int64         \n",
      " 33  State                            558211 non-null  int64         \n",
      " 34  County                           558211 non-null  int64         \n",
      " 35  NoOfMonths_PartACov              558211 non-null  int64         \n",
      " 36  NoOfMonths_PartBCov              558211 non-null  int64         \n",
      " 37  ChronicCond_Alzheimer            558211 non-null  int64         \n",
      " 38  ChronicCond_Heartfailure         558211 non-null  int64         \n",
      " 39  ChronicCond_KidneyDisease        558211 non-null  int64         \n",
      " 40  ChronicCond_Cancer               558211 non-null  int64         \n",
      " 41  ChronicCond_ObstrPulmonary       558211 non-null  int64         \n",
      " 42  ChronicCond_Depression           558211 non-null  int64         \n",
      " 43  ChronicCond_Diabetes             558211 non-null  int64         \n",
      " 44  ChronicCond_IschemicHeart        558211 non-null  int64         \n",
      " 45  ChronicCond_Osteoporasis         558211 non-null  int64         \n",
      " 46  ChronicCond_rheumatoidarthritis  558211 non-null  int64         \n",
      " 47  ChronicCond_stroke               558211 non-null  int64         \n",
      " 48  IPAnnualReimbursementAmt         558211 non-null  int64         \n",
      " 49  IPAnnualDeductibleAmt            558211 non-null  int64         \n",
      " 50  OPAnnualReimbursementAmt         558211 non-null  int64         \n",
      " 51  OPAnnualDeductibleAmt            558211 non-null  int64         \n",
      " 52  PotentialFraud                   558211 non-null  object        \n",
      " 53  Patient_Deceased                 558211 non-null  int64         \n",
      " 54  AdmitForDays                     558211 non-null  float64       \n",
      "dtypes: datetime64[ns](1), float64(8), int64(30), object(16)\n",
      "memory usage: 234.2+ MB\n"
     ]
    }
   ],
   "source": [
    "final_data.info()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "14d126a4",
   "metadata": {},
   "source": [
    "## Nodes Features Creation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "fd3a1a8a",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "from torch_geometric.data import HeteroData\n",
    "from sklearn.preprocessing import OneHotEncoder, StandardScaler\n",
    "\n",
    "prov_ids = final_data['Provider'].unique()\n",
    "bene_ids = final_data['BeneID'].unique()\n",
    "prov_map = {pid: i for i, pid in enumerate(prov_ids)}\n",
    "bene_map = {bid: i for i, bid in enumerate(bene_ids)}\n",
    "\n",
    "# Provider node features matrix\n",
    "# 1) PROVIDER FEATURES\n",
    "prov_cols = [\n",
    "    'InscClaimAmtReimbursed', 'DeductibleAmtPaid', 'IP_indicator', 'State', \n",
    "    'AttendingPhysician', 'OperatingPhysician', 'OtherPhysician',\n",
    "] \n",
    "\n",
    "prov_raw = (\n",
    "    final_data[prov_cols + ['Provider']]\n",
    "    .drop_duplicates('Provider')\n",
    "    .set_index('Provider')\n",
    ")\n",
    "\n",
    "num_cols = [c for c in prov_cols if c not in ('Provider')]\n",
    "prov_num_scaled = StandardScaler().fit_transform(prov_raw[num_cols])\n",
    "\n",
    "prov_raw_feats = torch.tensor(\n",
    "    np.hstack([prov_num_scaled]),\n",
    "    dtype=torch.float32\n",
    ")\n",
    "\n",
    "prov_agg = (\n",
    "    final_data\n",
    "      .groupby('Provider')\n",
    "      .agg(\n",
    "        cnt=('Provider','count'),\n",
    "        insc_mean=('InscClaimAmtReimbursed','mean'),\n",
    "        insc_sum =('InscClaimAmtReimbursed','sum'),\n",
    "        insc_std =('InscClaimAmtReimbursed','std'),\n",
    "        insc_min =('InscClaimAmtReimbursed','min'),\n",
    "        insc_max =('InscClaimAmtReimbursed','max'),\n",
    "        ded_mean =('DeductibleAmtPaid','mean'),\n",
    "        ded_sum  =('DeductibleAmtPaid','sum'),\n",
    "        ded_std  =('DeductibleAmtPaid','std'),\n",
    "        ded_min  =('DeductibleAmtPaid','min'),\n",
    "        ded_max  =('DeductibleAmtPaid','max'),\n",
    "        ip_frac  =('IP_indicator','mean'),\n",
    "        distinct_bene=('BeneID','nunique'),\n",
    "      )\n",
    ")\n",
    "\n",
    "prov_agg = prov_agg.reindex(prov_ids).fillna(0)\n",
    "\n",
    "prov_agg_scaled = StandardScaler().fit_transform(prov_agg.values)\n",
    "prov_agg_feats   = torch.tensor(prov_agg_scaled, dtype=torch.float32)\n",
    "\n",
    "prov_feats = torch.cat([prov_raw_feats, prov_agg_feats], dim=1)\n",
    "\n",
    "\n",
    "# Get one row per provider, carrying the PotentialFraud flag\n",
    "label_df = (\n",
    "    final_data[['Provider','PotentialFraud']]\n",
    "    .drop_duplicates(subset='Provider')\n",
    "    .set_index('Provider')\n",
    ")\n",
    "\n",
    "label_df['PotentialFraud'] = label_df['PotentialFraud'].map({'Yes': 1, 'No': 0})\n",
    "\n",
    "\n",
    "# Pre-allocate tensors in prov_map order\n",
    "num_prov = len(prov_map)\n",
    "prov_labels = torch.zeros(num_prov, dtype=torch.long)\n",
    "\n",
    "for pid, idx in prov_map.items():\n",
    "    prov_labels[idx] = int(label_df.loc[pid, 'PotentialFraud'])\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "8f970615",
   "metadata": {},
   "outputs": [],
   "source": [
    "bene_cols = [\n",
    "    'BeneID', 'Gender', 'Race',\n",
    "    'ChronicCond_Alzheimer','ChronicCond_Heartfailure','ChronicCond_KidneyDisease',\n",
    "    'ChronicCond_Cancer','ChronicCond_ObstrPulmonary','ChronicCond_Depression',\n",
    "    'ChronicCond_Diabetes','ChronicCond_IschemicHeart','ChronicCond_Osteoporasis',\n",
    "    'ChronicCond_rheumatoidarthritis','ChronicCond_stroke',\n",
    "    'NoOfMonths_PartACov','NoOfMonths_PartBCov'\n",
    "]\n",
    "bene_raw = (\n",
    "    final_data[bene_cols]\n",
    "    .drop_duplicates('BeneID')\n",
    "    .set_index('BeneID')\n",
    ")\n",
    "\n",
    "# one-hot the categoricals\n",
    "enc = OneHotEncoder(sparse_output=False, handle_unknown='ignore')\n",
    "bene_cat_ohe = enc.fit_transform(bene_raw[['Gender','Race']].astype(str))\n",
    "\n",
    "num_cols = [c for c in bene_cols if c not in ('Gender', 'Race', 'BeneID')]\n",
    "bene_num_scaled = StandardScaler().fit_transform(bene_raw[num_cols])\n",
    "\n",
    "bene_raw_feats = torch.tensor(\n",
    "    np.hstack([bene_cat_ohe, bene_num_scaled]),\n",
    "    dtype=torch.float32\n",
    ")\n",
    "\n",
    "bene_agg = final_data.groupby('BeneID').agg({\n",
    "    'ClaimID': 'count',\n",
    "    'InscClaimAmtReimbursed': ['mean','sum','std'],\n",
    "    'DeductibleAmtPaid':       ['mean'],\n",
    "    'Provider':              pd.Series.nunique,\n",
    "    })\n",
    "\n",
    "bene_agg.columns = ['_'.join(col) for col in bene_agg.columns]\n",
    "bene_agg = bene_agg.reindex(bene_ids).fillna(0)\n",
    "\n",
    "bene_agg_scaled = StandardScaler().fit_transform(bene_agg.values)\n",
    "bene_agg_feats   = torch.tensor(bene_agg_scaled, dtype=torch.float32)\n",
    "\n",
    "bene_feats = torch.cat([bene_raw_feats, bene_agg_feats], dim=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "2978fb7e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 3) BUILD HETEROGENEOUS DATA OBJECT\n",
    "data = HeteroData()\n",
    "data['provider'].x = prov_feats\n",
    "data['provider'].y = prov_labels\n",
    "data['beneficiary'].x = bene_feats"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4c4c7ebd",
   "metadata": {},
   "source": [
    "## Edges Creation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "7924a35c",
   "metadata": {},
   "outputs": [],
   "source": [
    "import itertools\n",
    "\n",
    "# Each row is one claim edge\n",
    "src = final_data['Provider'].map(prov_map).values\n",
    "dst = final_data['BeneID'].map(bene_map).values\n",
    "stacked = np.stack((src, dst), axis=0) \n",
    "edge_charge = torch.tensor(stacked, dtype=torch.long)\n",
    "\n",
    "proj_edges = set()\n",
    "for bid, group in final_data.groupby('BeneID')['Provider']:\n",
    "    prov_idxs = [prov_map[p] for p in group.unique()]\n",
    "    for u, v in itertools.combinations(prov_idxs, 2):\n",
    "        proj_edges.add((u, v))\n",
    "        proj_edges.add((v, u))\n",
    "\n",
    "edge_proj = torch.tensor(list(zip(*proj_edges)), dtype=torch.long)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "a036c73e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Edge sets\n",
    "data['provider', 'charges', 'beneficiary'].edge_index = edge_charge\n",
    "data['provider', 'proj_provider', 'provider'].edge_index = edge_proj\n",
    "\n",
    "data['beneficiary', 'rev_charges', 'provider'].edge_index = edge_charge.flip(0)\n",
    "data['provider', 'rev_proj', 'provider'].edge_index      = edge_proj.flip(0)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6fec1a0d",
   "metadata": {},
   "source": [
    "## Train Test Split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "d9111c5c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train / Val / Test sizes: 3246 1082 1082\n"
     ]
    }
   ],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "# ── 1) get all provider node indices and their labels\n",
    "num_prov    = data['provider'].num_nodes\n",
    "all_indices = np.arange(num_prov)\n",
    "labels      = data['provider'].y.numpy()        # 0/1 array\n",
    "\n",
    "# ── 2) first split: train vs (val+test)\n",
    "train_idx, temp_idx, y_train, y_temp = train_test_split(\n",
    "    all_indices,\n",
    "    labels,\n",
    "    test_size=0.4,           # 60% train, 40% temp\n",
    "    stratify=labels,\n",
    "    random_state=42\n",
    ")\n",
    "\n",
    "# ── 3) second split: val vs test (split the 40% temp in half)\n",
    "val_idx, test_idx, y_val, y_test = train_test_split(\n",
    "    temp_idx,\n",
    "    y_temp,\n",
    "    test_size=0.5,           # results in 20% val, 20% test\n",
    "    stratify=y_temp,\n",
    "    random_state=42\n",
    ")\n",
    "\n",
    "# ── 4) create masks and attach to your HeteroData\n",
    "train_mask = torch.zeros(num_prov, dtype=torch.bool)\n",
    "val_mask   = torch.zeros(num_prov, dtype=torch.bool)\n",
    "test_mask  = torch.zeros(num_prov, dtype=torch.bool)\n",
    "\n",
    "train_mask[train_idx] = True\n",
    "val_mask[val_idx]     = True\n",
    "test_mask[test_idx]   = True\n",
    "\n",
    "data['provider'].train_mask = train_mask\n",
    "data['provider'].val_mask   = val_mask\n",
    "data['provider'].test_mask  = test_mask\n",
    "\n",
    "# ── 5) sanity check\n",
    "print(\"Train / Val / Test sizes:\",\n",
    "      train_mask.sum().item(),\n",
    "      val_mask.sum().item(),\n",
    "      test_mask.sum().item())\n",
    "# should reflect roughly a 60/20/20 split, with stratified fraud ratios\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "3b992fea",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import torch\n",
    "\n",
    "# 1.1 get the train indices for provider nodes\n",
    "train_idx = data['provider'].train_mask.nonzero(as_tuple=True)[0].numpy()\n",
    "\n",
    "# 1.2 extract their labels\n",
    "train_labels = data['provider'].y[train_idx].numpy()\n",
    "\n",
    "# 1.3 count how many of each class\n",
    "class_counts = np.bincount(train_labels)            # e.g. [#nonfraud, #fraud]\n",
    "class_weights = 1.0 / class_counts                   # inverse frequency\n",
    "\n",
    "# 1.4 convert to a tensor for loss weighting\n",
    "weight_tensor = torch.tensor(class_weights, dtype=torch.float)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "74770fa7",
   "metadata": {},
   "outputs": [],
   "source": [
    "from torch.utils.data import WeightedRandomSampler\n",
    "\n",
    "# 2.1 assign each train sample the weight of its class\n",
    "sample_weights = class_weights[train_labels]         # shape = (num_train,)\n",
    "\n",
    "# 2.2 create the sampler\n",
    "sampler = WeightedRandomSampler(\n",
    "    weights=sample_weights,\n",
    "    num_samples=len(sample_weights),\n",
    "    replacement=True         # allows oversampling of minority class\n",
    ")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "9749aeb8",
   "metadata": {},
   "outputs": [],
   "source": [
    "from torch_geometric.loader import NeighborLoader\n",
    "\n",
    "train_loader = NeighborLoader(\n",
    "    data,\n",
    "    input_nodes=('provider', train_idx),\n",
    "    num_neighbors=[20, 10],      # e.g. two GNN layers\n",
    "    batch_size=64,\n",
    "    sampler=sampler,             # ← our imbalance-aware sampler\n",
    "    shuffle=False                # sampler already shuffles\n",
    ")\n",
    "\n",
    "# 2) VALIDATION loader (no sampler!)\n",
    "val_loader = NeighborLoader(\n",
    "    data,\n",
    "    input_nodes=('provider', val_idx),\n",
    "    num_neighbors=[20, 10],\n",
    "    batch_size=64,\n",
    "    shuffle=False,\n",
    ")\n",
    "\n",
    "# 3) TEST loader (also no sampler)\n",
    "test_loader = NeighborLoader(\n",
    "    data,\n",
    "    input_nodes=('provider', test_idx),\n",
    "    num_neighbors=[20, 10],\n",
    "    batch_size=64,\n",
    "    shuffle=False,\n",
    ")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "c696700d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "HeteroData(\n",
      "  provider={\n",
      "    x=[3882, 20],\n",
      "    y=[3882],\n",
      "    train_mask=[3882],\n",
      "    val_mask=[3882],\n",
      "    test_mask=[3882],\n",
      "    n_id=[3882],\n",
      "    num_sampled_nodes=[3],\n",
      "    input_id=[64],\n",
      "    batch_size=64,\n",
      "  },\n",
      "  beneficiary={\n",
      "    x=[7964, 25],\n",
      "    n_id=[7964],\n",
      "    num_sampled_nodes=[3],\n",
      "  },\n",
      "  (provider, charges, beneficiary)={\n",
      "    edge_index=[2, 4265],\n",
      "    e_id=[4265],\n",
      "    num_sampled_edges=[2],\n",
      "  },\n",
      "  (provider, proj_provider, provider)={\n",
      "    edge_index=[2, 12313],\n",
      "    e_id=[12313],\n",
      "    num_sampled_edges=[2],\n",
      "  },\n",
      "  (beneficiary, rev_charges, provider)={\n",
      "    edge_index=[2, 12111],\n",
      "    e_id=[12111],\n",
      "    num_sampled_edges=[2],\n",
      "  },\n",
      "  (provider, rev_proj, provider)={\n",
      "    edge_index=[2, 12313],\n",
      "    e_id=[12313],\n",
      "    num_sampled_edges=[2],\n",
      "  }\n",
      ")\n",
      "Total provider nodes in this subgraph: 3882\n",
      "Root provider nodes (batch_size):     64\n",
      "   Labels in roots: [39 25] → 39.0625 % fraud\n",
      "   Labels in entire subgraph: [3409  473] → 12.184441009788769 % fraud\n",
      "provider.x shape: torch.Size([3882, 20])\n",
      "charges edge_index shape: torch.Size([2, 4265])\n"
     ]
    }
   ],
   "source": [
    "# grab one batch\n",
    "batch = next(iter(train_loader))\n",
    "\n",
    "# 1) inspect its overall structure\n",
    "print(batch)\n",
    "# should show something like: HeteroDataBatch(...)\n",
    "# with numbers of nodes/edges per type\n",
    "\n",
    "# 2) check how many provider nodes in total vs. how many root providers\n",
    "total_prov = batch['provider'].num_nodes\n",
    "root_bs    = batch['provider'].batch_size\n",
    "print(f\"Total provider nodes in this subgraph: {total_prov}\")\n",
    "print(f\"Root provider nodes (batch_size):     {root_bs}\")\n",
    "\n",
    "# 3) inspect the label distribution among the root nodes\n",
    "y_root = batch['provider'].y[:root_bs].cpu().numpy()\n",
    "print(\"   Labels in roots:\", np.bincount(y_root), \n",
    "      \"→\", 100*y_root.mean(), \"% fraud\")\n",
    "\n",
    "# 4) inspect the full-label distribution (should match global imbalance)\n",
    "y_all = batch['provider'].y.cpu().numpy()\n",
    "print(\"   Labels in entire subgraph:\", np.bincount(y_all),\n",
    "      \"→\", 100*y_all.mean(), \"% fraud\")\n",
    "\n",
    "# 5) verify your feature/edge tensors exist and have expected shapes\n",
    "print(\"provider.x shape:\", batch['provider'].x.shape)\n",
    "print(\"charges edge_index shape:\", batch['provider','charges','beneficiary'].edge_index.shape)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f7b7e8ce",
   "metadata": {},
   "source": [
    "## GNN Model Training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "42150068",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn.functional as F\n",
    "from torch_geometric.nn import SAGEConv, HeteroConv, BatchNorm, GraphNorm\n",
    "\n",
    "class HeteroSAGE(torch.nn.Module):\n",
    "    def __init__(self, hidden_channels, out_channels, dropout_p=0.1):\n",
    "        super().__init__()\n",
    "        # 1st hetero‐aggregation layer\n",
    "        self.conv1 = HeteroConv({\n",
    "            ('provider','charges','beneficiary'):    SAGEConv((-1, -1), hidden_channels),\n",
    "            ('provider','proj_provider','provider'): SAGEConv((-1, -1), hidden_channels),\n",
    "            ('beneficiary','rev_charges','provider'):SAGEConv((-1, -1), hidden_channels),\n",
    "            ('provider','rev_proj','provider'):      SAGEConv((-1, -1), hidden_channels),\n",
    "        }, aggr='mean')\n",
    "\n",
    "        # GraphNorm per node type\n",
    "        self.norm1 = torch.nn.ModuleDict({\n",
    "            'provider':    GraphNorm(hidden_channels),\n",
    "            'beneficiary': GraphNorm(hidden_channels),\n",
    "        })\n",
    "\n",
    "        # 2nd hetero‐aggregation layer\n",
    "        self.conv2 = HeteroConv({\n",
    "            ('provider','charges','beneficiary'):    SAGEConv((hidden_channels, hidden_channels), hidden_channels),\n",
    "            ('provider','proj_provider','provider'): SAGEConv((hidden_channels, hidden_channels), hidden_channels),\n",
    "            ('beneficiary','rev_charges','provider'):SAGEConv((hidden_channels, hidden_channels), hidden_channels),\n",
    "            ('provider','rev_proj','provider'):      SAGEConv((hidden_channels, hidden_channels), hidden_channels),\n",
    "        }, aggr='mean')\n",
    "\n",
    "        # another round of GraphNorm\n",
    "        self.norm2 = torch.nn.ModuleDict({\n",
    "            'provider':    GraphNorm(hidden_channels),\n",
    "            'beneficiary': GraphNorm(hidden_channels),\n",
    "        })\n",
    "\n",
    "        self.dropout = torch.nn.Dropout(p=dropout_p)\n",
    "        self.lin     = torch.nn.Linear(hidden_channels, out_channels)\n",
    "\n",
    "    def forward(self, x_dict, edge_index_dict):\n",
    "        # --- 1st layer + GraphNorm + ReLU + Dropout ---\n",
    "        x_dict = self.conv1(x_dict, edge_index_dict)\n",
    "        for ntype, x in x_dict.items():\n",
    "            x = self.norm1[ntype](x)     # per-node-type GraphNorm\n",
    "            x = F.relu(x)\n",
    "            x = self.dropout(x)\n",
    "            x_dict[ntype] = x\n",
    "\n",
    "        # --- 2nd layer + GraphNorm + ReLU + Dropout ---\n",
    "        x_dict = self.conv2(x_dict, edge_index_dict)\n",
    "        for ntype, x in x_dict.items():\n",
    "            x = self.norm2[ntype](x)\n",
    "            x = F.relu(x)\n",
    "            x = self.dropout(x)\n",
    "            x_dict[ntype] = x\n",
    "\n",
    "        # --- final provider logits ---\n",
    "        return self.lin(x_dict['provider'])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "08abc209",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "from torch.optim.lr_scheduler import ReduceLROnPlateau\n",
    "from sklearn.metrics import classification_report\n",
    "\n",
    "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "model = HeteroSAGE(hidden_channels=64, out_channels=2).to(device)\n",
    "optimizer = torch.optim.Adam(model.parameters(), lr=0.005, weight_decay=5e-4)\n",
    "\n",
    "# # compute class‐weights once from your training split\n",
    "# train_idx = data['provider'].train_mask.nonzero(as_tuple=True)[0].numpy()\n",
    "# counts = np.bincount(data['provider'].y[train_idx].numpy())\n",
    "# class_weights = torch.tensor(1.0 / counts, dtype=torch.float).to(device)\n",
    "# # criterion = torch.nn.CrossEntropyLoss(weight=class_weights)\n",
    "\n",
    "counts = np.bincount(train_labels)\n",
    "inv = 1.0 / counts\n",
    "inv = np.clip(inv, 1.0, 5.0)               # cap at 5×\n",
    "weight_tensor = torch.tensor(inv, dtype=torch.float).to(device)\n",
    "# criterion = nn.CrossEntropyLoss(weight=weight_tensor)\n",
    "\n",
    "\n",
    "# 1) FocalLoss definition\n",
    "class FocalLoss(nn.Module):\n",
    "    def __init__(self, gamma=2.0, weight=None):\n",
    "        super().__init__()\n",
    "        self.gamma = gamma\n",
    "        self.weight = weight\n",
    "    def forward(self, logits, targets):\n",
    "        # compute per-sample CE\n",
    "        ce = F.cross_entropy(logits, targets, weight=self.weight, reduction='none')\n",
    "        p_t = torch.exp(-ce)                        # model's estimated prob for true class\n",
    "        loss = ((1 - p_t) ** self.gamma * ce).mean()\n",
    "        return loss\n",
    "    \n",
    "criterion = FocalLoss(gamma=2.0, weight=weight_tensor.to(device))\n",
    "scheduler = ReduceLROnPlateau(\n",
    "    optimizer,\n",
    "    mode='min',       # we want to minimize validation loss\n",
    "    factor=0.5,       # LR ← LR * 0.5 on plateau\n",
    "    patience=2,       # wait 2 epochs with no improvement\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "19f2b82d",
   "metadata": {},
   "source": [
    "## With Threshold"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "618933c2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Optimal threshold τ = 0.55 → F1 = 0.1744\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import torch.nn.functional as F\n",
    "from sklearn.metrics import f1_score\n",
    "\n",
    "@torch.no_grad()\n",
    "def find_best_threshold(loader):\n",
    "    model.eval()\n",
    "    probs, labels = [], []\n",
    "    \n",
    "    for batch in loader:\n",
    "        batch = batch.to(device)\n",
    "        \n",
    "        out = model(batch.x_dict, batch.edge_index_dict)          # [N_sub, 2]\n",
    "        bs  = batch['provider'].batch_size                       # number of root nodes\n",
    "        p1  = F.softmax(out, dim=1)[:bs, 1].cpu().numpy()        # fraud-prob for roots\n",
    "        y   = batch['provider'].y[:bs].cpu().numpy()             # true labels for roots\n",
    "        \n",
    "        probs.append(p1)\n",
    "        labels.append(y)\n",
    "    \n",
    "    probs  = np.concatenate(probs)\n",
    "    labels = np.concatenate(labels)\n",
    "    \n",
    "    best_tau, best_f1 = 0.5, 0.0\n",
    "    for tau in np.linspace(0.0, 1.0, 101):\n",
    "        preds = (probs > tau).astype(int)\n",
    "        f1    = f1_score(labels, preds)\n",
    "        if f1 > best_f1:\n",
    "            best_f1, best_tau = f1, tau\n",
    "    \n",
    "    print(f\"Optimal threshold τ = {best_tau:.2f} → F1 = {best_f1:.4f}\")\n",
    "    return best_tau\n",
    "\n",
    "# Run it once after training (or after your final validation pass):\n",
    "tau = find_best_threshold(val_loader)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "8a3c6030",
   "metadata": {},
   "outputs": [],
   "source": [
    "def train():\n",
    "    model.train()\n",
    "    total_loss = 0\n",
    "    for batch in train_loader:\n",
    "        batch = batch.to(device)\n",
    "        optimizer.zero_grad()\n",
    "        out = model(batch.x_dict, batch.edge_index_dict)\n",
    "        loss = criterion(out, batch['provider'].y)\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "        total_loss += loss.item() * batch['provider'].y.size(0)\n",
    "    return total_loss / len(train_loader.dataset)\n",
    "\n",
    "\n",
    "@torch.no_grad()\n",
    "def evaluate(loader, split_name, threshold=0.5):\n",
    "    model.eval()\n",
    "    total_loss = 0.0\n",
    "    total_samples = 0\n",
    "    all_preds, all_labels = [], []\n",
    "\n",
    "    for batch in loader:\n",
    "        batch = batch.to(device)\n",
    "\n",
    "        # 1) forward\n",
    "        out_all = model(batch.x_dict, batch.edge_index_dict)      # [N_sub, 2]\n",
    "\n",
    "        # 2) isolate the root nodes\n",
    "        bs       = batch['provider'].batch_size\n",
    "        out_root = out_all[:bs]                                   # [batch_size, 2]\n",
    "        y_root   = batch['provider'].y[:bs]                       # [batch_size]\n",
    "\n",
    "        # 3) loss on root nodes\n",
    "        loss = criterion(out_root, y_root)\n",
    "        total_loss   += loss.item() * bs\n",
    "        total_samples += bs\n",
    "\n",
    "        # 4) compute fraud‐probabilities and apply threshold\n",
    "        probs = F.softmax(out_root, dim=1)[:,1].cpu().numpy()     # P(class=1)\n",
    "        preds = (probs > threshold).astype(int)\n",
    "\n",
    "        all_preds.append(preds)\n",
    "        all_labels.append(y_root.cpu().numpy())\n",
    "\n",
    "    avg_loss = total_loss / total_samples\n",
    "    all_preds  = np.concatenate(all_preds)\n",
    "    all_labels = np.concatenate(all_labels)\n",
    "\n",
    "    print(f\"\\n=== {split_name} (τ={threshold:.2f}, Loss {avg_loss:.4f}) ===\")\n",
    "    print(classification_report(all_labels, all_preds, digits=4, zero_division=0))\n",
    "\n",
    "    return avg_loss\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "9af03d71",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 01 — Train Loss: 3.9530\n",
      "\n",
      "=== Validation (τ=0.50, Loss 0.0658) ===\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0     0.9840    0.8787    0.9284       981\n",
      "           1     0.4223    0.8614    0.5668       101\n",
      "\n",
      "    accuracy                         0.8771      1082\n",
      "   macro avg     0.7032    0.8700    0.7476      1082\n",
      "weighted avg     0.9316    0.8771    0.8946      1082\n",
      "\n",
      "Epoch 02 — Train Loss: 2.8522\n",
      "\n",
      "=== Validation (τ=0.50, Loss 0.0612) ===\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0     0.9852    0.8797    0.9295       981\n",
      "           1     0.4272    0.8713    0.5733       101\n",
      "\n",
      "    accuracy                         0.8789      1082\n",
      "   macro avg     0.7062    0.8755    0.7514      1082\n",
      "weighted avg     0.9331    0.8789    0.8962      1082\n",
      "\n",
      "Epoch 03 — Train Loss: 2.4916\n",
      "\n",
      "=== Validation (τ=0.50, Loss 0.0771) ===\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0     0.9894    0.8603    0.9204       981\n",
      "           1     0.4017    0.9109    0.5576       101\n",
      "\n",
      "    accuracy                         0.8651      1082\n",
      "   macro avg     0.6956    0.8856    0.7390      1082\n",
      "weighted avg     0.9346    0.8651    0.8865      1082\n",
      "\n",
      "Epoch 04 — Train Loss: 2.2454\n",
      "\n",
      "=== Validation (τ=0.50, Loss 0.0472) ===\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0     0.9858    0.9215    0.9526       981\n",
      "           1     0.5333    0.8713    0.6617       101\n",
      "\n",
      "    accuracy                         0.9168      1082\n",
      "   macro avg     0.7596    0.8964    0.8071      1082\n",
      "weighted avg     0.9436    0.9168    0.9254      1082\n",
      "\n",
      "Epoch 05 — Train Loss: 1.9869\n",
      "\n",
      "=== Validation (τ=0.50, Loss 0.0798) ===\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0     0.9952    0.8542    0.9194       981\n",
      "           1     0.4042    0.9604    0.5689       101\n",
      "\n",
      "    accuracy                         0.8641      1082\n",
      "   macro avg     0.6997    0.9073    0.7441      1082\n",
      "weighted avg     0.9401    0.8641    0.8867      1082\n",
      "\n",
      "Epoch 06 — Train Loss: 1.9487\n",
      "\n",
      "=== Validation (τ=0.50, Loss 0.0687) ===\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0     0.9942    0.8716    0.9288       981\n",
      "           1     0.4324    0.9505    0.5944       101\n",
      "\n",
      "    accuracy                         0.8789      1082\n",
      "   macro avg     0.7133    0.9110    0.7616      1082\n",
      "weighted avg     0.9417    0.8789    0.8976      1082\n",
      "\n",
      "Epoch 07 — Train Loss: 1.8392\n",
      "\n",
      "=== Validation (τ=0.50, Loss 0.0279) ===\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0     0.9784    0.9694    0.9739       981\n",
      "           1     0.7273    0.7921    0.7583       101\n",
      "\n",
      "    accuracy                         0.9529      1082\n",
      "   macro avg     0.8528    0.8807    0.8661      1082\n",
      "weighted avg     0.9550    0.9529    0.9538      1082\n",
      "\n",
      "Epoch 08 — Train Loss: 1.7924\n",
      "\n",
      "=== Validation (τ=0.50, Loss 0.0668) ===\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0     0.9943    0.8848    0.9364       981\n",
      "           1     0.4593    0.9505    0.6194       101\n",
      "\n",
      "    accuracy                         0.8909      1082\n",
      "   macro avg     0.7268    0.9177    0.7779      1082\n",
      "weighted avg     0.9443    0.8909    0.9068      1082\n",
      "\n",
      "Epoch 09 — Train Loss: 1.6609\n",
      "\n",
      "=== Validation (τ=0.50, Loss 0.0435) ===\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0     0.9913    0.9297    0.9595       981\n",
      "           1     0.5741    0.9208    0.7072       101\n",
      "\n",
      "    accuracy                         0.9288      1082\n",
      "   macro avg     0.7827    0.9252    0.8334      1082\n",
      "weighted avg     0.9524    0.9288    0.9359      1082\n",
      "\n",
      "Epoch 10 — Train Loss: 1.7206\n",
      "\n",
      "=== Validation (τ=0.50, Loss 0.0451) ===\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0     0.9891    0.9256    0.9563       981\n",
      "           1     0.5549    0.9010    0.6868       101\n",
      "\n",
      "    accuracy                         0.9233      1082\n",
      "   macro avg     0.7720    0.9133    0.8215      1082\n",
      "weighted avg     0.9486    0.9233    0.9311      1082\n",
      "\n",
      "Epoch 11 — Train Loss: 1.4121\n",
      "\n",
      "=== Validation (τ=0.50, Loss 0.0232) ===\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0     0.9906    0.9664    0.9783       981\n",
      "           1     0.7360    0.9109    0.8142       101\n",
      "\n",
      "    accuracy                         0.9612      1082\n",
      "   macro avg     0.8633    0.9386    0.8962      1082\n",
      "weighted avg     0.9668    0.9612    0.9630      1082\n",
      "\n",
      "Epoch 12 — Train Loss: 1.3083\n",
      "\n",
      "=== Validation (τ=0.50, Loss 0.0346) ===\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0     0.9925    0.9388    0.9649       981\n",
      "           1     0.6104    0.9307    0.7373       101\n",
      "\n",
      "    accuracy                         0.9381      1082\n",
      "   macro avg     0.8014    0.9348    0.8511      1082\n",
      "weighted avg     0.9568    0.9381    0.9437      1082\n",
      "\n",
      "Epoch 13 — Train Loss: 1.3540\n",
      "\n",
      "=== Validation (τ=0.50, Loss 0.0260) ===\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0     0.9895    0.9613    0.9752       981\n",
      "           1     0.7054    0.9010    0.7913       101\n",
      "\n",
      "    accuracy                         0.9556      1082\n",
      "   macro avg     0.8475    0.9311    0.8832      1082\n",
      "weighted avg     0.9630    0.9556    0.9580      1082\n",
      "\n",
      "Epoch 14 — Train Loss: 1.2988\n",
      "\n",
      "=== Validation (τ=0.50, Loss 0.0336) ===\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0     0.9936    0.9450    0.9687       981\n",
      "           1     0.6376    0.9406    0.7600       101\n",
      "\n",
      "    accuracy                         0.9445      1082\n",
      "   macro avg     0.8156    0.9428    0.8643      1082\n",
      "weighted avg     0.9603    0.9445    0.9492      1082\n",
      "\n",
      "Epoch 15 — Train Loss: 1.1353\n",
      "\n",
      "=== Validation (τ=0.50, Loss 0.0205) ===\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0     0.9907    0.9755    0.9831       981\n",
      "           1     0.7931    0.9109    0.8479       101\n",
      "\n",
      "    accuracy                         0.9695      1082\n",
      "   macro avg     0.8919    0.9432    0.9155      1082\n",
      "weighted avg     0.9722    0.9695    0.9704      1082\n",
      "\n",
      "Epoch 16 — Train Loss: 1.1141\n",
      "\n",
      "=== Validation (τ=0.50, Loss 0.0317) ===\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0     0.9936    0.9511    0.9719       981\n",
      "           1     0.6643    0.9406    0.7787       101\n",
      "\n",
      "    accuracy                         0.9501      1082\n",
      "   macro avg     0.8290    0.9458    0.8753      1082\n",
      "weighted avg     0.9629    0.9501    0.9538      1082\n",
      "\n",
      "Epoch 17 — Train Loss: 1.0814\n",
      "\n",
      "=== Validation (τ=0.50, Loss 0.0208) ===\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0     0.9917    0.9745    0.9830       981\n",
      "           1     0.7881    0.9208    0.8493       101\n",
      "\n",
      "    accuracy                         0.9695      1082\n",
      "   macro avg     0.8899    0.9477    0.9162      1082\n",
      "weighted avg     0.9727    0.9695    0.9706      1082\n",
      "\n",
      "Epoch 18 — Train Loss: 1.0550\n",
      "\n",
      "=== Validation (τ=0.50, Loss 0.0152) ===\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0     0.9918    0.9867    0.9893       981\n",
      "           1     0.8774    0.9208    0.8986       101\n",
      "\n",
      "    accuracy                         0.9806      1082\n",
      "   macro avg     0.9346    0.9538    0.9439      1082\n",
      "weighted avg     0.9811    0.9806    0.9808      1082\n",
      "\n",
      "Epoch 19 — Train Loss: 1.1035\n",
      "\n",
      "=== Validation (τ=0.50, Loss 0.0149) ===\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0     0.9819    0.9959    0.9889       981\n",
      "           1     0.9540    0.8218    0.8830       101\n",
      "\n",
      "    accuracy                         0.9797      1082\n",
      "   macro avg     0.9680    0.9089    0.9359      1082\n",
      "weighted avg     0.9793    0.9797    0.9790      1082\n",
      "\n",
      "Epoch 20 — Train Loss: 1.0152\n",
      "\n",
      "=== Validation (τ=0.50, Loss 0.0171) ===\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0     0.9938    0.9766    0.9851       981\n",
      "           1     0.8051    0.9406    0.8676       101\n",
      "\n",
      "    accuracy                         0.9732      1082\n",
      "   macro avg     0.8994    0.9586    0.9263      1082\n",
      "weighted avg     0.9762    0.9732    0.9741      1082\n",
      "\n",
      "Epoch 21 — Train Loss: 1.0037\n",
      "\n",
      "=== Validation (τ=0.50, Loss 0.0297) ===\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0     0.9968    0.9460    0.9707       981\n",
      "           1     0.6490    0.9703    0.7778       101\n",
      "\n",
      "    accuracy                         0.9482      1082\n",
      "   macro avg     0.8229    0.9581    0.8742      1082\n",
      "weighted avg     0.9643    0.9482    0.9527      1082\n",
      "\n",
      "Epoch 22 — Train Loss: 1.0010\n",
      "\n",
      "=== Validation (τ=0.50, Loss 0.0170) ===\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0     0.9928    0.9857    0.9893       981\n",
      "           1     0.8704    0.9307    0.8995       101\n",
      "\n",
      "    accuracy                         0.9806      1082\n",
      "   macro avg     0.9316    0.9582    0.9444      1082\n",
      "weighted avg     0.9814    0.9806    0.9809      1082\n",
      "\n",
      "Epoch 23 — Train Loss: 0.9294\n",
      "\n",
      "=== Validation (τ=0.50, Loss 0.0217) ===\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0     0.9958    0.9613    0.9782       981\n",
      "           1     0.7185    0.9604    0.8220       101\n",
      "\n",
      "    accuracy                         0.9612      1082\n",
      "   macro avg     0.8571    0.9608    0.9001      1082\n",
      "weighted avg     0.9699    0.9612    0.9636      1082\n",
      "\n",
      "Epoch 24 — Train Loss: 0.8884\n",
      "\n",
      "=== Validation (τ=0.50, Loss 0.0152) ===\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0     0.9938    0.9878    0.9908       981\n",
      "           1     0.8879    0.9406    0.9135       101\n",
      "\n",
      "    accuracy                         0.9834      1082\n",
      "   macro avg     0.9408    0.9642    0.9521      1082\n",
      "weighted avg     0.9840    0.9834    0.9836      1082\n",
      "\n",
      "Epoch 25 — Train Loss: 0.8823\n",
      "\n",
      "=== Validation (τ=0.50, Loss 0.0235) ===\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0     0.9968    0.9582    0.9771       981\n",
      "           1     0.7050    0.9703    0.8167       101\n",
      "\n",
      "    accuracy                         0.9593      1082\n",
      "   macro avg     0.8509    0.9643    0.8969      1082\n",
      "weighted avg     0.9696    0.9593    0.9622      1082\n",
      "\n",
      "Epoch 26 — Train Loss: 0.8383\n",
      "\n",
      "=== Validation (τ=0.50, Loss 0.0240) ===\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0     0.9958    0.9613    0.9782       981\n",
      "           1     0.7185    0.9604    0.8220       101\n",
      "\n",
      "    accuracy                         0.9612      1082\n",
      "   macro avg     0.8571    0.9608    0.9001      1082\n",
      "weighted avg     0.9699    0.9612    0.9636      1082\n",
      "\n",
      "Epoch 27 — Train Loss: 0.8302\n",
      "\n",
      "=== Validation (τ=0.50, Loss 0.0184) ===\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0     0.9969    0.9704    0.9835       981\n",
      "           1     0.7717    0.9703    0.8596       101\n",
      "\n",
      "    accuracy                         0.9704      1082\n",
      "   macro avg     0.8843    0.9704    0.9216      1082\n",
      "weighted avg     0.9758    0.9704    0.9719      1082\n",
      "\n",
      "Epoch 28 — Train Loss: 0.8317\n",
      "\n",
      "=== Validation (τ=0.50, Loss 0.0141) ===\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0     0.9928    0.9857    0.9893       981\n",
      "           1     0.8704    0.9307    0.8995       101\n",
      "\n",
      "    accuracy                         0.9806      1082\n",
      "   macro avg     0.9316    0.9582    0.9444      1082\n",
      "weighted avg     0.9814    0.9806    0.9809      1082\n",
      "\n",
      "Epoch 29 — Train Loss: 0.8177\n",
      "\n",
      "=== Validation (τ=0.50, Loss 0.0169) ===\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0     0.9959    0.9786    0.9871       981\n",
      "           1     0.8220    0.9604    0.8858       101\n",
      "\n",
      "    accuracy                         0.9769      1082\n",
      "   macro avg     0.9089    0.9695    0.9365      1082\n",
      "weighted avg     0.9796    0.9769    0.9777      1082\n",
      "\n",
      "Epoch 30 — Train Loss: 0.7988\n",
      "\n",
      "=== Validation (τ=0.50, Loss 0.0176) ===\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0     0.9927    0.9745    0.9835       981\n",
      "           1     0.7899    0.9307    0.8545       101\n",
      "\n",
      "    accuracy                         0.9704      1082\n",
      "   macro avg     0.8913    0.9526    0.9190      1082\n",
      "weighted avg     0.9738    0.9704    0.9715      1082\n",
      "\n",
      "Epoch 31 — Train Loss: 0.7974\n",
      "\n",
      "=== Validation (τ=0.50, Loss 0.0209) ===\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0     0.9947    0.9613    0.9777       981\n",
      "           1     0.7164    0.9505    0.8170       101\n",
      "\n",
      "    accuracy                         0.9603      1082\n",
      "   macro avg     0.8556    0.9559    0.8974      1082\n",
      "weighted avg     0.9687    0.9603    0.9627      1082\n",
      "\n",
      "Epoch 32 — Train Loss: 0.7942\n",
      "\n",
      "=== Validation (τ=0.50, Loss 0.0141) ===\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0     0.9938    0.9827    0.9882       981\n",
      "           1     0.8482    0.9406    0.8920       101\n",
      "\n",
      "    accuracy                         0.9787      1082\n",
      "   macro avg     0.9210    0.9616    0.9401      1082\n",
      "weighted avg     0.9802    0.9787    0.9792      1082\n",
      "\n",
      "Epoch 33 — Train Loss: 0.7833\n",
      "\n",
      "=== Validation (τ=0.50, Loss 0.0149) ===\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0     0.9928    0.9827    0.9877       981\n",
      "           1     0.8468    0.9307    0.8868       101\n",
      "\n",
      "    accuracy                         0.9778      1082\n",
      "   macro avg     0.9198    0.9567    0.9372      1082\n",
      "weighted avg     0.9792    0.9778    0.9783      1082\n",
      "\n",
      "Epoch 34 — Train Loss: 0.7689\n",
      "\n",
      "=== Validation (τ=0.50, Loss 0.0146) ===\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0     0.9948    0.9817    0.9882       981\n",
      "           1     0.8421    0.9505    0.8930       101\n",
      "\n",
      "    accuracy                         0.9787      1082\n",
      "   macro avg     0.9185    0.9661    0.9406      1082\n",
      "weighted avg     0.9806    0.9787    0.9793      1082\n",
      "\n",
      "Epoch 35 — Train Loss: 0.7642\n",
      "\n",
      "=== Validation (τ=0.50, Loss 0.0123) ===\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0     0.9959    0.9878    0.9918       981\n",
      "           1     0.8899    0.9604    0.9238       101\n",
      "\n",
      "    accuracy                         0.9852      1082\n",
      "   macro avg     0.9429    0.9741    0.9578      1082\n",
      "weighted avg     0.9860    0.9852    0.9855      1082\n",
      "\n",
      "Epoch 36 — Train Loss: 0.7494\n",
      "\n",
      "=== Validation (τ=0.50, Loss 0.0127) ===\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0     0.9938    0.9847    0.9892       981\n",
      "           1     0.8636    0.9406    0.9005       101\n",
      "\n",
      "    accuracy                         0.9806      1082\n",
      "   macro avg     0.9287    0.9627    0.9449      1082\n",
      "weighted avg     0.9817    0.9806    0.9810      1082\n",
      "\n",
      "Epoch 37 — Train Loss: 0.7455\n",
      "\n",
      "=== Validation (τ=0.50, Loss 0.0117) ===\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0     0.9939    0.9908    0.9923       981\n",
      "           1     0.9135    0.9406    0.9268       101\n",
      "\n",
      "    accuracy                         0.9861      1082\n",
      "   macro avg     0.9537    0.9657    0.9596      1082\n",
      "weighted avg     0.9864    0.9861    0.9862      1082\n",
      "\n",
      "Epoch 38 — Train Loss: 0.7513\n",
      "\n",
      "=== Validation (τ=0.50, Loss 0.0120) ===\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0     0.9949    0.9878    0.9913       981\n",
      "           1     0.8889    0.9505    0.9187       101\n",
      "\n",
      "    accuracy                         0.9843      1082\n",
      "   macro avg     0.9419    0.9691    0.9550      1082\n",
      "weighted avg     0.9850    0.9843    0.9845      1082\n",
      "\n",
      "Epoch 39 — Train Loss: 0.7536\n",
      "\n",
      "=== Validation (τ=0.50, Loss 0.0133) ===\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0     0.9948    0.9837    0.9892       981\n",
      "           1     0.8571    0.9505    0.9014       101\n",
      "\n",
      "    accuracy                         0.9806      1082\n",
      "   macro avg     0.9260    0.9671    0.9453      1082\n",
      "weighted avg     0.9820    0.9806    0.9810      1082\n",
      "\n",
      "Epoch 40 — Train Loss: 0.7608\n",
      "\n",
      "=== Validation (τ=0.50, Loss 0.0128) ===\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0     0.9949    0.9847    0.9898       981\n",
      "           1     0.8649    0.9505    0.9057       101\n",
      "\n",
      "    accuracy                         0.9815      1082\n",
      "   macro avg     0.9299    0.9676    0.9477      1082\n",
      "weighted avg     0.9827    0.9815    0.9819      1082\n",
      "\n",
      "Epoch 41 — Train Loss: 0.7489\n",
      "\n",
      "=== Validation (τ=0.50, Loss 0.0120) ===\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0     0.9949    0.9878    0.9913       981\n",
      "           1     0.8889    0.9505    0.9187       101\n",
      "\n",
      "    accuracy                         0.9843      1082\n",
      "   macro avg     0.9419    0.9691    0.9550      1082\n",
      "weighted avg     0.9850    0.9843    0.9845      1082\n",
      "\n",
      "Epoch 42 — Train Loss: 0.7468\n",
      "\n",
      "=== Validation (τ=0.50, Loss 0.0110) ===\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0     0.9949    0.9878    0.9913       981\n",
      "           1     0.8889    0.9505    0.9187       101\n",
      "\n",
      "    accuracy                         0.9843      1082\n",
      "   macro avg     0.9419    0.9691    0.9550      1082\n",
      "weighted avg     0.9850    0.9843    0.9845      1082\n",
      "\n",
      "Epoch 43 — Train Loss: 0.7386\n",
      "\n",
      "=== Validation (τ=0.50, Loss 0.0123) ===\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0     0.9949    0.9888    0.9918       981\n",
      "           1     0.8972    0.9505    0.9231       101\n",
      "\n",
      "    accuracy                         0.9852      1082\n",
      "   macro avg     0.9460    0.9696    0.9574      1082\n",
      "weighted avg     0.9858    0.9852    0.9854      1082\n",
      "\n",
      "Epoch 44 — Train Loss: 0.7396\n",
      "\n",
      "=== Validation (τ=0.50, Loss 0.0106) ===\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0     0.9959    0.9878    0.9918       981\n",
      "           1     0.8899    0.9604    0.9238       101\n",
      "\n",
      "    accuracy                         0.9852      1082\n",
      "   macro avg     0.9429    0.9741    0.9578      1082\n",
      "weighted avg     0.9860    0.9852    0.9855      1082\n",
      "\n",
      "Epoch 45 — Train Loss: 0.7421\n",
      "\n",
      "=== Validation (τ=0.50, Loss 0.0115) ===\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0     0.9949    0.9878    0.9913       981\n",
      "           1     0.8889    0.9505    0.9187       101\n",
      "\n",
      "    accuracy                         0.9843      1082\n",
      "   macro avg     0.9419    0.9691    0.9550      1082\n",
      "weighted avg     0.9850    0.9843    0.9845      1082\n",
      "\n",
      "Epoch 46 — Train Loss: 0.7374\n",
      "\n",
      "=== Validation (τ=0.50, Loss 0.0133) ===\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0     0.9948    0.9817    0.9882       981\n",
      "           1     0.8421    0.9505    0.8930       101\n",
      "\n",
      "    accuracy                         0.9787      1082\n",
      "   macro avg     0.9185    0.9661    0.9406      1082\n",
      "weighted avg     0.9806    0.9787    0.9793      1082\n",
      "\n",
      "Epoch 47 — Train Loss: 0.7481\n",
      "\n",
      "=== Validation (τ=0.50, Loss 0.0129) ===\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0     0.9949    0.9867    0.9908       981\n",
      "           1     0.8807    0.9505    0.9143       101\n",
      "\n",
      "    accuracy                         0.9834      1082\n",
      "   macro avg     0.9378    0.9686    0.9525      1082\n",
      "weighted avg     0.9842    0.9834    0.9836      1082\n",
      "\n",
      "Epoch 48 — Train Loss: 0.7480\n",
      "\n",
      "=== Validation (τ=0.50, Loss 0.0122) ===\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0     0.9949    0.9878    0.9913       981\n",
      "           1     0.8889    0.9505    0.9187       101\n",
      "\n",
      "    accuracy                         0.9843      1082\n",
      "   macro avg     0.9419    0.9691    0.9550      1082\n",
      "weighted avg     0.9850    0.9843    0.9845      1082\n",
      "\n",
      "Epoch 49 — Train Loss: 0.7361\n",
      "\n",
      "=== Validation (τ=0.50, Loss 0.0124) ===\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0     0.9949    0.9867    0.9908       981\n",
      "           1     0.8807    0.9505    0.9143       101\n",
      "\n",
      "    accuracy                         0.9834      1082\n",
      "   macro avg     0.9378    0.9686    0.9525      1082\n",
      "weighted avg     0.9842    0.9834    0.9836      1082\n",
      "\n",
      "Epoch 50 — Train Loss: 0.7400\n",
      "\n",
      "=== Validation (τ=0.50, Loss 0.0128) ===\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0     0.9949    0.9857    0.9903       981\n",
      "           1     0.8727    0.9505    0.9100       101\n",
      "\n",
      "    accuracy                         0.9824      1082\n",
      "   macro avg     0.9338    0.9681    0.9501      1082\n",
      "weighted avg     0.9835    0.9824    0.9828      1082\n",
      "\n",
      "Optimal threshold τ = 0.55 → F1 = 0.9360\n",
      "\n",
      "=== Validation (τ=0.55, Loss 0.0129) ===\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0     0.9939    0.9908    0.9923       981\n",
      "           1     0.9135    0.9406    0.9268       101\n",
      "\n",
      "    accuracy                         0.9861      1082\n",
      "   macro avg     0.9537    0.9657    0.9596      1082\n",
      "weighted avg     0.9864    0.9861    0.9862      1082\n",
      "\n",
      "\n",
      "=== Test (τ=0.55, Loss 0.0214) ===\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0     0.9959    0.9908    0.9934       981\n",
      "           1     0.9151    0.9604    0.9372       101\n",
      "\n",
      "    accuracy                         0.9880      1082\n",
      "   macro avg     0.9555    0.9756    0.9653      1082\n",
      "weighted avg     0.9884    0.9880    0.9881      1082\n",
      "\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "0.021438345982729288"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# 4) Main training loop with LR scheduling\n",
    "num_epochs = 50\n",
    "best_val = float('inf')\n",
    "\n",
    "for epoch in range(1, num_epochs+1):\n",
    "    tr_loss = train()\n",
    "    print(f\"Epoch {epoch:02d} — Train Loss: {tr_loss:.4f}\")\n",
    "    val_loss = evaluate(val_loader, \"Validation\", threshold=0.5)\n",
    "    scheduler.step(val_loss)\n",
    "\n",
    "# 2) Find the best threshold τ on the validation set\n",
    "tau = find_best_threshold(val_loader)\n",
    "\n",
    "# 3) Re‐evaluate with that τ\n",
    "evaluate(val_loader, \"Validation\", threshold=tau)\n",
    "evaluate(test_loader,  \"Test\",       threshold=tau)\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "PyG",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
